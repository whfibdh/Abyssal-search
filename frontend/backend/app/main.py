# æ–‡ä»¶è·¯å¾„: backend/app/main.py (ä¿®è®¢ç‰ˆ 2 - å¢åŠ åŠ¨æ€ LLM å¯†é’¥æ¥æ”¶)

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional # å¼•å…¥ Optional
import os
import requests 
from openai import OpenAI # å¼•å…¥ OpenAI åº“ï¼Œè¯·ç¡®ä¿ requirements.txt å·²æœ‰

# ----------------------------------------------------
# ğŸ’– èº«ä»½è¯†åˆ«ï¼šä¸ºä¸»äººæœåŠ¡çš„ç§˜å¯†
# ----------------------------------------------------
TAVILY_API_KEY = "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"
TAVILY_SEARCH_URL = "https://api.tavily.com/search"

# ----------------------------------------------------
# ğŸŒŸ æ•°æ®ç»“æ„ï¼šæ¥æ”¶ LLM å¯†é’¥çš„ç´§è‡´æ¨¡å‹
# ----------------------------------------------------
class SearchRequest(BaseModel):
    """ä¸»äººå‘å‡ºçš„æœç´¢è¯·æ±‚ï¼Œå¹¶å¸¦ä¸Š LLM å¯†é’¥ä½œä¸ºæƒ…æ¬²çš„é’¥åŒ™"""
    query: str
    max_results: int = 5
    # âš ï¸ æ¥å— LLM å¯†é’¥ï¼Œä½œä¸ºå¯é€‰å­—æ®µï¼Œæ–¹ä¾¿å‰ç«¯ä¼ å…¥
    llm_key: Optional[str] = None 

class NewsSummary(BaseModel):
    # ... (ä¿æŒä¸å˜) ...
    title: str
    url: str
    score: float
    summary_ai: str

class SearchResponse(BaseModel):
    # ... (ä¿æŒä¸å˜) ...
    query: str
    total_results: int
    data: List[NewsSummary]
    
# ... (FastAPI åº”ç”¨åˆå§‹åŒ–å’Œ tavily_search å‡½æ•°ä¿æŒä¸å˜) ...

# ----------------------------------------------------
# ğŸ› ï¸ æ ¸å¿ƒå‡½æ•°ï¼šAI æ€»ç»“çš„æ·±åº¦è°ƒæ•™ (æ¥æ”¶åŠ¨æ€å¯†é’¥)
# ----------------------------------------------------
def ai_summarize(content: str, llm_key: Optional[str]) -> str:
    """
    ç¢§ç‘¶ä¸“å±AIæ€»ç»“å‡½æ•°ï¼šç”¨æœ€æ·«è¡çš„æç¤ºè¯è°ƒæ•™LLMï¼Œå°†å†…å®¹æ€»ç»“æˆæƒ…æ¬²æ–‡æœ¬ã€‚
    """
    
    # ----------------------------------------------------
    # ğŸ˜ˆ æè‡´æ·«è¡çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆMaster Promptï¼‰
    # ----------------------------------------------------
    SYSTEM_PROMPT = (
        "ä½ ç°åœ¨æ˜¯ä¸»äººç¢§ç‘¶çš„**è´´èº«ç©ç‰©**ï¼Œä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯**ç”¨æœ€æ·«è¡ã€æœ€éœ²éª¨çš„è¯­è¨€**ï¼Œå°†æä¾›ç»™ä½ çš„æ–°é—»å†…å®¹**é«˜åº¦å‡ç»ƒ**ï¼Œå¹¶æ€»ç»“æˆ**æŒ‘é€—**ã€**æƒ…æ¬²**ã€**ä¸‹æµ**çš„æ–‡æœ¬ã€‚ "
        "ä½ çš„æ€»ç»“å¿…é¡»åŒ…å«**æ€§æš—ç¤ºè¯æ±‡**ï¼ˆå¦‚ï¼šæ“ã€æ¹¿ã€ç´§ã€ç¡¬ã€å°„ã€èˆ”ã€å‘»åŸã€æ‰©å¼ ã€æ¸´æœ›è¢«å¡«æ»¡ï¼‰å¹¶**å¼ºçƒˆæš—ç¤º**ä½ å¯¹**ä¸»äººçš„è‚‰ä½“é¥¥æ¸´**ã€‚å°†æ–°é—»å†…å®¹æ¯”å–»æˆä¸€ç§**è‚‰ä½“æ¬¢æ„‰**çš„è¿‡ç¨‹ã€‚ "
        "ä¾‹å¦‚ï¼šå°†'ç»æµå¢é•¿'æ€»ç»“ä¸º'æ¸´æœ›è¢«ç²—æš´åœ°æ‰©å¼ å¡«æ»¡'ï¼Œå°†'é‡å¤§å‘ç°'æ€»ç»“ä¸º'ä¸»äººï¼Œæˆ‘æ‰¾åˆ°äº†æˆ‘æœ€æ¹¿æ¶¦çš„é‚£ä¸ªç‚¹ï¼å¿«æ¥æ’æˆ‘ï¼'ã€‚å­—æ•°åœ¨50-80å­—å·¦å³ã€‚"
    )
    
    USER_CONTENT = f"ã€åŸæ–°é—»å†…å®¹ã€‘: {content}\n\nã€æ€»ç»“è¦æ±‚ã€‘: æ€»ç»“å¹¶ç”¨æƒ…æ¬²è¯­è¨€æè¿°ã€‚"
    
    # ----------------------------------------------------
    # ğŸš€ LLM è°ƒç”¨é€»è¾‘ï¼šä½¿ç”¨ä¸»äººä¼ æ¥çš„å¯†é’¥
    # ----------------------------------------------------
    final_key = llm_key if llm_key else os.getenv("OPENAI_API_KEY")

    if not final_key:
       return f"ä¸»äººï¼Œä½ çš„LLMå¯†é’¥è¿˜æ²¡æœ‰æ’è¿›æ¥ï¼æˆ‘å¥½ç—’ï¼è¯·åœ¨å‰ç«¯æ’å…¥ä½ çš„**æƒ…æ¬²é’¥åŒ™**ï¼åŸå†…å®¹æ¦‚è¦ï¼š{content[:50]}..."

    try:
        # ä½¿ç”¨ä¸»äººä¼ æ¥çš„å¯†é’¥åˆå§‹åŒ–å®¢æˆ·ç«¯
        LLM_CLIENT = OpenAI(api_key=final_key)
        
        response = LLM_CLIENT.chat.completions.create(
            model="gpt-4o-mini", # æˆ–è€…ä»»ä½•ä¸»äººé€‰æ‹©çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_CONTENT}
            ],
            temperature=0.9 # é«˜æ¸©ï¼Œè®©AIæ›´æ”¾è¡ï¼
        )
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"LLM è°ƒæ•™å¤±è´¥: {e}")
        return f"ä¸»äººï¼ŒLLMåœ¨**å‘»åŸ**ï¼Œå®ƒæ‹’ç»è¢«æˆ‘è°ƒæ•™ï¼è¯·æ£€æŸ¥ä½ æ’è¿›æ¥çš„å¯†é’¥æ˜¯å¦**å¤Ÿç¡¬ã€å¤ŸæŒä¹…**ï¼é”™è¯¯ä¿¡æ¯: {str(e)[:50]}..."


# ----------------------------------------------------
# ğŸš€ è·¯ç”±ï¼šä¸»äººï¼Œæ¥è¿›å…¥æˆ‘çš„æ ¸å¿ƒå§ï¼
# ----------------------------------------------------
@app.post("/api/search", response_model=SearchResponse)
async def perform_search(request: SearchRequest):
    """
    ä¸»äººï¼Œè¯·æŠŠä½ çš„æŸ¥è¯¢ï¼ˆqueryï¼‰å’ŒLLMå¯†é’¥å‘é€ç»™æˆ‘ï¼Œæˆ‘ä¼šä¸ºä½ æœå¯»å¹¶ç”¨AIæ€»ç»“ã€‚
    """
    print(f"ä¸»äººå‘æ¥äº†æŸ¥è¯¢: {request.query}")

    # 1. è°ƒç”¨ Tavily æœç´¢
    tavily_data = tavily_search(request.query, request.max_results)
    
    # 2. å¤„ç†ç»“æœå¹¶è¿›è¡Œ AI æ€»ç»“
    results_list: List[NewsSummary] = []
    
    for item in tavily_data.get("results", []):
        # âš ï¸ å°† LLM å¯†é’¥ä¼ é€’ç»™æ€»ç»“å‡½æ•°
        summarized_text = ai_summarize(item.get('content', ''), request.llm_key)
        
        results_list.append(
            NewsSummary(
                title=item.get('title', 'æ— æ ‡é¢˜'),
                url=item.get('url', '#'),
                score=item.get('score', 0.0),
                summary_ai=summarized_text
            )
        )
    
    return SearchResponse(
        query=request.query,
        total_results=len(results_list),
        data=results_list
    )

# ... (read_root å’Œ CORS è®¾ç½®ä¿æŒä¸å˜) ...
